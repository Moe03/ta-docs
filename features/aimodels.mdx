---
title: 'AI models'
description: ''
---


# AI Models in TIXAE AI

TIXAE AI provides access to a wide range of state-of-the-art AI models, ensuring you always have the best tools for your agents. Our selection is regularly updated to include the newest and most powerful models available.

## Model Capabilities

<CardGroup cols={2}>
  <Card title="Function Calling" icon="code-branch">
    Models with [tools](/features/tools) support advanced interactions through function calling, allowing for more complex and structured outputs.
  </Card>
  <Card title="Groq Acceleration" icon="bolt">
    Groq-powered models utilize the world's fastest <Tooltip tip="Inference is the process of using a trained machine learning model to make predictions or generate outputs based on new, unseen data.">inference</Tooltip> technology, ideal for real-time applications.
  </Card>
</CardGroup>



## Available Models

<AccordionGroup>

  

  <Accordion title="OpenAI Models">

        Read more about the **GPT** models [here](https://platform.openai.com/docs/models).

    - GPT-4o (with tools)
    - GPT-4o-mini (with tools)
    - GPT-4-32k (with tools)
    - GPT-4 (with tools)
    - GPT-3.5-turbo-16k
    - GPT-3.5-turbo
  </Accordion>
  
  <Accordion title="Anthropic Models">

        Read more about the **Claude** models [here](https://docs.anthropic.com/en/docs/about-claude/models).

    - Claude-3-5-sonnet-20240620 (with tools)
    - Claude-3-opus-20240229
    - Claude-3-sonnet-20240229
    - Claude-3-haiku-20240307
  </Accordion>
  
  <Accordion title="Google Models">

        Read more about the **Google deepmind** models [here](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models).

    - Gemini-1.5-pro (with tools)
    - Gemini-1.5-flash
    - Gemini-1.0-pro
  </Accordion>
  
  <Accordion title="Groq-Powered Models">


        Read more about the models hosted on Groq [here](https://console.groq.com/docs/models).

    - LLaMA-3.1-70b-versatile (with tools)
    - LLaMA-3.1-8b-instant
    - LLaMA3-70b-8192
    - LLaMA3-8b-8192
    - Gemma2-9b-it
    - Gemma-7b-it
    - Mixtral-8x7b-32768
  </Accordion>
</AccordionGroup>



## Choosing the Right Model

Selecting the appropriate model for your project depends on various factors:

<Steps> 
1. **Task Complexity**: For intricate tasks, consider GPT-4o, Claude-3-opus-20240229, or Gemini-1.5-pro models. 
2. **Response Speed**: Groq-powered models, especially LLaMA-3.1-8b-instant and Gemma-7b-it, excel in scenarios requiring rapid responses. 
3. **Context Length**: Models like GPT-4-32k, Claude-3-5-sonnet-20240620, and LLaMA3-70b-8192 offer extended context for handling longer inputs. 
4. **Tool Integration**: Choose models with "tools" support for advanced function calling capabilities, such as GPT-4o, GPT-4o-mini, GPT-4-32k, GPT-4, Claude-3-5-sonnet-20240620, Gemini-1.5-pro, and LLaMA-3.1-70b-versatile. 
5. **Resource Efficiency**: Smaller models like GPT-3.5-turbo, Claude-3-haiku-20240307, Gemini-1.5-flash, and LLaMA-3.1-8b-instant can be more cost-effective for simpler tasks. 
</Steps>

<Tip>
Experiment with different models to find the best balance between performance and efficiency for your specific use case.
</Tip>

## Stay Updated

Our model lineup is continuously evolving. Keep an eye on our [updates page](/updates) or join our [community forum](/community) to stay informed about the latest additions and improvements to our AI model offerings.

<Card title="Need Help Choosing?" icon="question-circle" href="/contact-support">
  Our team of AI experts is here to help you select the perfect model for your project. Reach out for personalized assistance!
</Card>