---
title: "AI models"
description: ""
icon: robot
---

TIXAE AI provides access to a wide range of **state-of-the-art** AI models, ensuring that your agents are always equipped with the best and newest models on the market.

#

<Tip>
  As soon as **new models** are released, the TIXAE AI team promptly updates
  the platform. This means you typically get access to the latest and most
  powerful models **right away**.{" "}
</Tip>

## Model Capabilities

Having an understanding of the various models, their strengths and potential weaknesses allows you to leverage the right model for your specific use case, ensuring your agent is equipped to handle its task. These are the main points to consider when choosing:

<CardGroup cols={2}>
  <Card title="Function Calling" icon="code-branch">
    Models with [tools](/features/tools) support enable advanced interactions
    through function calling, allowing for communications with external APIs.
    This capability is crucial for tasks requiring specific data formats or
    integrations with external systems.
  </Card>
  <Card title="Groq Acceleration" icon="bolt">
    Groq-powered models leverage cutting-edge hardware for ultra-fast{" "}
    <Tooltip tip="Inference is the process of using a trained machine learning model to make predictions or generate outputs based on new, unseen data.">
      inference
    </Tooltip>
    , ideal for real-time applications. This technology significantly reduces
    latency, making these models perfect for scenarios where quick response
    times are critical.
  </Card>
  <Card title="Extended Context" icon="expand">
    Certain models offer larger{" "}
    <Tooltip tip="The context window is the amount of text a model can process in a single interaction, measured in tokens. Larger context windows allow for more comprehensive understanding and generation of content.">
      context windows
    </Tooltip>
    , allowing them to process and understand longer inputs. This is
    particularly useful for tasks involving extensive documents or complex,
    multi-turn conversations.
  </Card>
  <Card title="Task Specialization" icon="bullseye">
    Different models excel in various specialized tasks, such as code
    generation, creative writing, or analytical reasoning. Read our [prompt
    engingeering](/agent-creation/system-prompt/Overview) guide for more
    information on creating task specific agents.
  </Card>
</CardGroup>

## Available Models

<AccordionGroup>

  <Accordion title="OpenAI Models">

        Read more about the **GPT** models [here](https://platform.openai.com/docs/models).

    - GPT-4o (with tools)
    - GPT-4o-mini (with tools)
    - GPT-4-32k (with tools)
    - GPT-4 (with tools)
    - GPT-3.5-turbo-16k
    - GPT-3.5-turbo

  </Accordion>
  
  <Accordion title="Anthropic Models">

        Read more about the **Claude** models [here](https://docs.anthropic.com/en/docs/about-claude/models).

    - Claude-3-5-sonnet-20240620 (with tools)
    - Claude-3-opus-20240229
    - Claude-3-sonnet-20240229
    - Claude-3-haiku-20240307

  </Accordion>
  
  <Accordion title="Google Models">

        Read more about the **Google deepmind** models [here](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models).

    - Gemini-1.5-pro (with tools)
    - Gemini-1.5-flash
    - Gemini-1.0-pro

  </Accordion>
  
  <Accordion title="Groq-Powered Models">

        Read more about the models hosted on Groq [here](https://console.groq.com/docs/models).

    - LLaMA-3.1-70b-versatile (with tools)
    - LLaMA-3.1-8b-instant
    - LLaMA3-70b-8192
    - LLaMA3-8b-8192
    - Gemma2-9b-it
    - Gemma-7b-it
    - Mixtral-8x7b-32768

  </Accordion>
</AccordionGroup>

## Choosing the Right Model

Selecting the appropriate model for your project depends on various factors:

<Steps>
  <Step title="Task Complexity" icon="brain">
    For intricate tasks, consider `GPT-4o`, `Claude-3-opus-20240229` and
    `Claude-3-5-sonnet-20240620`, or `Gemini-1.5-pro` models.
  </Step>

  <Step title="Response Speed" icon="bolt">
    Groq-powered models, especially `LLaMA-3.1-8b-instant` and `Gemma-7b-it`,
    excel in scenarios requiring rapid responses.
  </Step>

  <Step title="Context Length" icon="arrow-up-right-dots">
    Models like `GPT-4-0 (128k)`, `Google Gemini 1.5 Pro (2 Million)`,
    `Claude-3-5-sonnet-20240620 (200k)`, and `LLaMA3-70b-8192 (128k)` offer
    extended context for handling longer inputs.
  </Step>

  <Step title="Tool Integration" icon="screwdriver-wrench">
    Choose models with [tools](/features/tools) support for advanced function
    calling capabilities, such as `GPT-4o`, `GPT-4o-mini`, `GPT-4-32k`, `GPT-4`,
    `Claude-3-5-sonnet-20240620`, `Gemini-1.5-pro`, and
    `LLaMA-3.1-70b-versatile`.
  </Step>

  <Step title="Resource Efficiency" icon="leaf">
    Smaller models like `GPT-3.5-turbo`, `GPT-4-o-mini`,
    `Claude-3-haiku-20240307`, `Gemini-1.5-flash`, and `LLaMA-3.1-8b-instant`
    can be more cost-effective and faster for simpler tasks.
  </Step>
</Steps>

<Tip>
  Experiment with different models to find the best balance between writing
  styles, capabilies and efficiency for your agents use case.
</Tip>

{/* TODO: Check if this is still relevant */}

{/* ## Stay Updated

Our model lineup is continuously evolving. Keep an eye on our [updates page](/updates) or join our [community forum](/community) to stay informed about the latest additions and improvements to our selection of AI models.

# */}

{/* <Card title="Need Help Designing?" icon="question" href="https://magicmark.ai">
  Our team of AI experts is here to help you select the perfect model for your
  project. Reach out for personalized assistance!
</Card> */}
